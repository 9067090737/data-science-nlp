{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Определение языка\n",
    "\n",
    "Необходимо решить задачу определения языка на коллекция из 383,108 текстов на 26 языках.\n",
    "\n",
    "### Подготовка данных\n",
    "\n",
    "Для начала посмотрим на [данные](https://www.dropbox.com/s/fkr16tbrh90bq78/TLI.zip?dl=0). Первая колонка здесь – метка класса (язык), вторая – текст, а разделены они табуляцией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_table('./data/data-lang-id.txt', sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('lang').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang    383111\n",
       "text    383108\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# что-то не так...\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang    383108\n",
       "text    383108\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выкинем строки, в которых есть пустые значения\n",
    "# и переназначим индексы\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно разбить данные на тренировочную и тестовую выборку. Кажется, они уже перемешаны, но на всякий случай перемешаем их перед разбиением еще раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132941</th>\n",
       "      <td>fr</td>\n",
       "      <td>Le plaisir qu’il y prenait se reflétait sur se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31184</th>\n",
       "      <td>ru</td>\n",
       "      <td>Алесь привязал коня к забору и медленно пошел ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255297</th>\n",
       "      <td>en</td>\n",
       "      <td>Ranged around the building in ring fashion, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198820</th>\n",
       "      <td>pl</td>\n",
       "      <td>Myślałem o Claire, o wieczorach, które u niej ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152289</th>\n",
       "      <td>ru</td>\n",
       "      <td>Кроме нас двоих, у нее нет никого на земле. Ск...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lang                                               text\n",
       "132941   fr  Le plaisir qu’il y prenait se reflétait sur se...\n",
       "31184    ru  Алесь привязал коня к забору и медленно пошел ...\n",
       "255297   en  Ranged around the building in ring fashion, th...\n",
       "198820   pl  Myślałem o Claire, o wieczorach, które u niej ...\n",
       "152289   ru  Кроме нас двоих, у нее нет никого на земле. Ск..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = shuffle(data)\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация\n",
    "\n",
    "Для работы необходимо векторизовать тексты. Это можно по-разному. Простейшие способы — `CountVectorizer` (мешок слов) и `TfidfVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мешок слов\n",
    "\n",
    "Это значит, что каждое слово или каждая N-грамма задает свою координату в векторном пространстве и никаких дополнительных признаков – например, порядок слов – не использует. \n",
    "\n",
    "**N-граммы** — это сочетания из N элементов (слов, символов), идущих друг за другом. Одиночные элементы называются униграммами, сочетания из двух элементов -- биграммами, из трёх — триграммами, а дальше 4-граммы, 5-граммы и т.д. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF\n",
    "\n",
    "Ещё один способ работы с текстовыми данными — [TF-IDF](https://en.wikipedia.org/wiki/Tf–idf) *(Term Frequency – Inverse Document Frequency)*. Рассмотрим коллекцию текстов $D$.  Для каждого уникального слова $t$ из документа $d \\in D$ вычислим следующие величины:\n",
    "\n",
    "**1. Term Frequency** – количество вхождений слова в отношении к общему числу слов в тексте:\n",
    "$$\\text{tf}(t, d) = \\frac{n_{td}}{\\sum_{t \\in d} n_{td}},$$\n",
    "где $n_{td}$ — количество вхождений слова $t$ в текст $d$.\n",
    "\n",
    "\n",
    "**2. Inverse Document Frequency**\n",
    "$$\\text{idf}(t, D) = \\log \\frac{\\left| D \\right|}{\\left| \\{d\\in D: t \\in d\\} \\right|},$$\n",
    "где $\\left| \\{d\\in D: t \\in d\\} \\right|$ – количество текстов в коллекции, содержащих слово $t$.\n",
    "\n",
    "Тогда для каждой пары (слово, текст) $(t, d)$ вычислим величину:\n",
    "$$\\text{tf-idf}(t,d, D) = \\text{tf}(t, d)\\cdot \\text{idf}(t, D).$$\n",
    "\n",
    "Отметим, что значение $\\text{tf}(t, d)$ корректируется для часто встречающихся общеупотребимых слов при помощи значения $\\text{idf}(t, D).$\n",
    "\n",
    "Признаковым описанием одного объекта $d \\in D$ будет вектор $\\bigg(\\text{tf-idf}(t,d, D)\\bigg)_{t\\in V}$, где $V$ – словарь всех слов, встречающихся в коллекции $D$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим показания классификатора на тестовом множестве. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Важность признаков\n",
    "\n",
    "Веса признаков в линейной модели в случае, если признаки отмасштабированы, характеризуют степень их влияния на значение целевой переменной. В задаче классификации текстов, кроме того, признаки являются хорошо интерпретируемыми, поскольку каждый из них соответствует конкретному слову. Изучим влияние конкретных слов на значение целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_weights = zip(vectorizer.get_feature_names(), classifier.coef_[0])\n",
    "f_weights = sorted(f_weights, key=lambda i: i[1])\n",
    "for i in range(1,30):\n",
    "    print('%s, %.2f' % f_weights[-i])\n",
    "    \n",
    "print('...')\n",
    "for i in reversed(range(1,10)):\n",
    "    print('%s, %.2f' % f_weights[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание\n",
    "\n",
    "1. Векторизовать тексты с помощью `TfidfVectorizer` и проверить, влияет ли это на качество результатов классификации.\n",
    "2. Скачать датасет [20newsgroups](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html) и проделать то же самое с ними. В данном случае предсказывать мы будем тему новости, и, поскольку эта задача сложнее, можно сравнить качество при использовании лемматизации и без, при удалении стоп-слов и без, при разных способах векторизации, а также сравнить разные классификаторы."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
