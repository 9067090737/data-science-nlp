{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача классификации в NLP\n",
    "\n",
    "## Виды\n",
    "\n",
    "1. Бинарная классификация: $C = \\{0, 1\\}$ \n",
    "2. Многоклассовая классификация [multiclass classification]: $C = \\{0, ..., K\\}$\n",
    "3. Многотемная классификация [multi-label classification]: $C = \\{0,1\\}^K$\n",
    "\n",
    "\n",
    "* $d \\in D$ – документы\n",
    "* $c \\in C$ – классы \n",
    "\n",
    "## Примеры\n",
    "\n",
    "* Фильтрация спама: $C = \\{spam, ham\\}$ – бинарная классификация\n",
    "* Классификация по тональности: $C =  \\{neutral, positive, negative\\}$ – классификация с тремя классами\n",
    "* Рубрикация: $C \\in \\{религия, праздники, спорт, фестивали, ... \\}$ – классификация на несколько тем\n",
    "* Определение авторства:\n",
    "    * Этим ли автором написан текст: $ C = \\{0, 1\\}$?\n",
    "    * Кем из этих авторов написан текст: $ C = \\{a_1, a_2, a_3, ... \\}$?\n",
    "    * Пол автора: $ C = \\{f, m\\}$\n",
    "    \n",
    "## Методы\n",
    "\n",
    "### По правилам\n",
    "\n",
    "* Если в предложении встречается личное местоимение первого лица и глагол с окончанием женского рода, то пол автора = $f$.\n",
    "* Если доля положительно окрашенных прилагательтельных в отзыве больше доли отрицательно окрашенных прилагательных, то отзыв относится к классу $posititive$.\n",
    "\n",
    "### С использованием алгоритмов машинного обучения \n",
    "\n",
    "$ \\gamma : D \\rightarrow C$ - алгоритм классификации\n",
    "\n",
    "$({D^{train}, C^{train}})$ – обучающее множество \n",
    "\n",
    "$({D^{test}, C^{test}})$ – тестовое множество "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метод наивного Байеса  (Multinomial naive Bayes classifier)\n",
    "\n",
    "Требуется оценить вероятность принадлежности документа $d \\in D$ классу $c \\in C$: $p(c|d)$. Каждый документ –  мешок слов, всего слов $|V|$.\n",
    "\t\n",
    "* $p(c)$ – априорная вероятность класса $c$\n",
    "* $p(c|d)$ – апостериорная вероятность класса $c$\n",
    "* $ p(c|d) = \\frac{p(d|c)p(c)}{p(d)} $\n",
    "\n",
    "\n",
    "В мультиномиальной байесовской модели документ – это последовательность событий. Каждое событие – этослучайный выбор одного слова из мешка слов.К огда мы подсчитываем правдоподобие документа, мы перемножаем вероятности того, что мы достали из мешка те самые слова, которые встретились в документе. \n",
    "\n",
    "Наивное предположение в том, что мы достаём из мешка разные слова независимо друг от друга, т.е. вероятности признаков внутри класса независимы.\n",
    "\n",
    "Получается мультиномиальная генеративная модель, которая учитывает количество повторений каждого слова, но не учитывает порядок этих слов, а также каких слов нетв документе.\n",
    "\n",
    "[Подробнее о различных видах байесовских классификаторов](https://logic.pdmi.ras.ru/~sergey/teaching/mlaptu11/03-classifiers.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Векторные модели (начало)\n",
    "\n",
    "Векторые представления лингвистических объектов (слов, предложений, текстов) являются одним из основных инструментов, используемых в компьютерной лингвистике. Они применяются во всех задачах, связанных с обработкой естественного языка. \n",
    "\n",
    "* $d \\in D$ – документы\n",
    "* $w \\in V$ – словарь, всего слов |V|\n",
    "\n",
    "* Традиционное представление: одно слово – одна размерность в векторной модели: $\\vec{d_i} = <f_1, ... , f_{|V|}> $\n",
    "* $f$ – компоненты вектора – могут быть:\n",
    "    * 0 и 1\n",
    "    * частотами\n",
    "    * $tf-idf$ весами\n",
    "* С использованием распределенных представлений слов *(word embeddings)*:\n",
    "    * покомпонентное среднее векторов слов, входящих в текст\n",
    "    * покомпонентный максимум векторов слов, входящих в текст\n",
    "* С использованием распределенных представлений текстов *(doc embeddings)*:\n",
    "    * doc2vec\n",
    "    * fastText\n",
    "    * снижение размерности в векторной модели, в т. ч. сингулярное разложение [singular value decomposition, SVD]\n",
    "    \n",
    "    \n",
    "### Виды векторизации\n",
    "\n",
    "* One-hot кодирование\n",
    "* Модель мешка слов\n",
    "* tf-idf\n",
    "* Матрицы совместной встречаемости\n",
    "* Латентно-семантический анализ (LSA)\n",
    "* Латентное размещение Дирихле (LDA)\n",
    "* Распределенное представление слов/документов (embeddings)\n",
    "\n",
    "\n",
    "### Терм-документная матрица\n",
    "\n",
    "**Терм-документная матрица** — матрица, которая описывает частоту «терминов» (т.е. слов) в коллекции документов. В терм-документной матрице строки соответствуют терминам, а столбцы — документам в коллекции. Что будет в ячейках матрицы зависит от способа векторизации:\n",
    "\n",
    "* 0 и 1 при one-hot encoding\n",
    "* абсолютная/относительная частота при модели мешка слов\n",
    "* tf-idf веса\n",
    "\n",
    "![td_matrix](./img/matrix.png)\n",
    "\n",
    "\n",
    "## Счетные векторные модели\n",
    "\n",
    "### One-hot кодирование\n",
    "\n",
    "Самый простой представить слова в векторном виде -- проиндексировать их и закодировать векторами, в которых все компоненты будут равны 0, а компонента, соответствующая индексу слова, равна 1. Иначе говоря, мы работаем с матрицей $W$ размерности $k$, где $k$ это число уникальных слов в корпусе, а в рядах и столбцах находятся все эти слова. Мы ставим в ячейку матрицы 1, если слово в строке и колонке совпадает. \n",
    "\n",
    "![OneHot](http://1.bp.blogspot.com/-_c2pVR3A0HQ/VogUStUgFbI/AAAAAAAADQc/6V1M6zmAJmA/s1600/1-hot-vector.png)\n",
    "\n",
    "Такое представление слов называется *one-hot encoding*. Оно может быть иногда полезно, когда мы хотим работать со словами как с категориальными признаками, но не несёт совершенно никакой информации о значении слов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Мешок слов\n",
    "\n",
    "**Мешок слов** *(bag of words, BoW)* — это векторная модель, где каждый документ или текст выглядит как неупорядоченный набор слов без сведений о связях между ними. Его можно представить в виде матрицы, каждая строка в которой соответствует отдельному документу или тексту, а каждый столбец — определенному слову. Ячейка на пересечении строки и столбца содержит *количество вхождений слова* в соответствующий документ.\n",
    "\n",
    "Это значит, что каждое слово или каждая N-грамма задает свою координату в векторном пространстве и никаких дополнительных признаков – например, порядок слов – не использует. \n",
    "\n",
    "![bow](./img/bow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "Ещё один способ работы с текстовыми данными — [TF-IDF](https://en.wikipedia.org/wiki/Tf–idf) *(Term Frequency – Inverse Document Frequency)*. Tf-idf — это модификация мешка слов, которая позволяет учитывать «важность» слова в документе. \n",
    "\n",
    "Рассмотрим коллекцию текстов $D$.  Для каждого уникального слова $t$ из документа $d \\in D$ вычислим следующие величины:\n",
    "\n",
    "**1. Term Frequency** – количество вхождений слова в отношении к общему числу слов в тексте:\n",
    "\n",
    "$\\text{tf}(t, d) = \\frac{n_{td}}{\\sum_{t \\in d} n_{td}},$\n",
    "\n",
    "где $n_{td}$ — количество вхождений слова $t$ в текст $d$. \n",
    "\n",
    "То есть по сути это мешок слов, только частота здесь не абсолютная, а относительная (нормированная на длину текста).\n",
    "\n",
    "\n",
    "**2. Inverse Document Frequency**\n",
    "$\\text{idf}(t, D) = \\log \\frac{\\left| D \\right|}{\\left| \\{d\\in D: t \\in d\\} \\right|},$\n",
    "\n",
    "где $\\left| \\{d\\in D: t \\in d\\} \\right|$ – количество текстов в коллекции, содержащих слово $t$.\n",
    "\n",
    "Тогда для каждой пары (слово, текст) $(t, d)$ вычислим величину:\n",
    "\n",
    "$\\text{tf-idf}(t,d, D) = \\text{tf}(t, d)\\cdot \\text{idf}(t, D).$\n",
    "\n",
    "Значение $\\text{tf}(t, d)$ корректируется для часто встречающихся общеупотребимых слов при помощи значения $\\text{idf}(t, D).$  Если слово встречается в множестве документов, то idf будет близка к 1, а если оно встречается в одном документе или в небольшом количестве документов, то она будет гораздо выше.\n",
    "\n",
    "Признаковым описанием одного объекта $d \\in D$ будет вектор $\\bigg(\\text{tf-idf}(t,d, D)\\bigg)_{t\\in V}$, где $V$ – словарь всех слов, встречающихся в коллекции $D$.\n",
    "\n",
    "Можно записать формулу расчет tf-idf чуть проще:\n",
    "\n",
    "\n",
    "<img src=\"./img/tfidf.png\" width=\"400\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Совместная встречаемость слов\n",
    "\n",
    "В предыдущих моделях мы никак не учитывали значение слова. Можно ли его как-то закодировать? Здесь к нам приходит на помощь лингвистическая теория, которая называется дистрибутивной гипотезой. Она утверждает, что значение слова определяется его контекстом — иначе говоря, словами, которые встречаются рядом с этим словом в тексте. Область лингвистики, которая занимается вычислением степени семантической близости между словами/текстами и т.п. на основании их распределения (дистрибуции) в больших массивах данных (текстовых корпусах) назвается **дистрибутивной семантикой**.\n",
    "\n",
    "Давайте будет подразумевать под контекстом некоторое число $n$ слева и справа от слова. Это число будем называть *окном*. К примеру, в предложении \"мама мыла раму\" окном размера 1 для слова \"мыла\" будет набор слов (\"мама\", \"раму\").\n",
    "\n",
    "Пусть теперь мы будем ставить в ячейку 1, если слово из *колонки* хоть раз встретилось внутри окна вокруг слова из *строки* во всём корпусе. \n",
    "\n",
    "![Binary](http://4.bp.blogspot.com/-JHmQeFhqgCU/VogqxZ2UdhI/AAAAAAAADQs/-rJ0QYDn_ws/s1600/distributional.png)\n",
    "\n",
    "Такая матрица называется **бинарной матрицей совместной встречаемости**, и она уже что-то говорит о значении слов. Тем не менее, с помощью неё все ещё трудно отличить слова, которые часто встречаются в похожих контекстах. Здесь довольно логичным кажется переход от бинарных значений к собственно количеству появлений слова $w_1$ в контексте слова $w_2$: иначе говоря, сколько раз в корпусе слово \"мыла\" встретилась рядом со словом \"мама\".\n",
    "\n",
    "### Метрики вероятности совместной встречаемости слов\n",
    "\n",
    "Бинарная и частотная матрицы это самые простые способы получения информации о контексте слова. Они не очень эффективны и не используют информацию о том, насколько характерно для данного документа само употребление слов в контексте.\n",
    "\n",
    "Метрика, которая лучше фиксирует эту информацию, называется PMI (Pointwise Mutual Information): здесь способ посчитать связь между двумя словами это узнать, насколько чаще они встречаются в корпусе вместе, чем если бы мы ожидали, что они появляются случайно. Иначе говоря, это мера того, как часто встречаются две случайные величины $w$ и $c$, по сравнению с тем, что мы ожидали бы, если бы они были независимыми:\n",
    "\n",
    "$$PMI_{w, c} =  \\log_2 \\frac{P(w, c)}{P(w)P(c)}.$$\n",
    "\n",
    "Значения PMI варьируются от -$\\infty$ до $\\infty$. Но отрицательные значения PMI, как правило, ненадежны: они говорят о том, что слова вместе встречаются реже, чем случайно. И если у нас нет очень большого корпуса, то эти редко встречающиеся пары слов будут зашумлять наши данные. По этой причине всегда лучше использовать метрику Positive PMI (сокращённо PPMI), которая заменяет все отрицательные значения PMI на ноль.\n",
    "\n",
    "$$PPMI_{w, c} = \\max(PMI_{w, c}, 0) = PMI_{w, c}^+$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание №1\n",
    "\n",
    "## Определение языка\n",
    "\n",
    "Необходимо решить задачу определения языка на коллекция из 383,108 текстов на 26 языках с помощью наивного байесовского классификатора. Влияет ли способ векторизации на результаты? Сильно ли меняется качество классификации при изменении различных параметров векторизатора и классификатора? Как можно оценить качество работы модели? Необзодимо также визуализировать результаты (например, построить матрицу ошибок).\n",
    "\n",
    "Чтобы класиифицировать тексты, нужно сначала их векторизовать. В `sklearn` реализованы, например, [модель мешка слов](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) (`CountVectorizer`) и [tf-idf](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) (`TfidfVectorizer`).\n",
    "\n",
    "Основные параметры:\n",
    "\n",
    "* lowercase: приводить к нижнему регистру или нет\n",
    "* ngram_range: например, (1, 3) значит, что будут использованы униграммы, биграммы и триграммы\n",
    "* analyzer: ‘word’ (слова), ‘char’ (символы), ‘char_wb’ (символы только внутри границ слова)\n",
    "* tokenizer: можно использовать свой токенизатор, а не встроенный\n",
    "* token_pattern: для встроенного токенизатора можно задать понятие токена в виде регулярки\n",
    "* stop_words: список стоп-слов, по умолчанию None\n",
    "* max_df: максимальная документная частота, от 0.0 до 1.0\n",
    "* min_df: минимальная документная частота, целое число (например, если min_df=5, то будут учитываться только слова, которые встречаются 5 и более раз)\n",
    "\n",
    "### Подготовка данных\n",
    "\n",
    "Для начала посмотрим на [данные](https://www.dropbox.com/s/bybdr0a3fod1j1a/data-lang-id.txt?dl=0). Первая колонка здесь – метка класса (язык), вторая – текст, а разделены они табуляцией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.metrics import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_table('./data/data-lang-id.txt', sep='\\t')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby('lang').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang    383111\n",
       "text    383108\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# что-то не так...\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang    383108\n",
       "text    383108\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выкинем строки, в которых есть пустые значения\n",
    "# и переназначим индексы\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нужно разбить данные на тренировочную и тестовую выборку. Кажется, они уже перемешаны, но на всякий случай перемешаем их перед разбиением еще раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lang</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132941</th>\n",
       "      <td>fr</td>\n",
       "      <td>Le plaisir qu’il y prenait se reflétait sur se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31184</th>\n",
       "      <td>ru</td>\n",
       "      <td>Алесь привязал коня к забору и медленно пошел ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255297</th>\n",
       "      <td>en</td>\n",
       "      <td>Ranged around the building in ring fashion, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198820</th>\n",
       "      <td>pl</td>\n",
       "      <td>Myślałem o Claire, o wieczorach, które u niej ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152289</th>\n",
       "      <td>ru</td>\n",
       "      <td>Кроме нас двоих, у нее нет никого на земле. Ск...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lang                                               text\n",
       "132941   fr  Le plaisir qu’il y prenait se reflétait sur se...\n",
       "31184    ru  Алесь привязал коня к забору и медленно пошел ...\n",
       "255297   en  Ranged around the building in ring fashion, th...\n",
       "198820   pl  Myślałem o Claire, o wieczorach, które u niej ...\n",
       "152289   ru  Кроме нас двоих, у нее нет никого на земле. Ск..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = shuffle(data)\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем данные и обучаем классификатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('vect', vectorizer),\n",
    "    ('clf', classifier),\n",
    "])\n",
    "\n",
    "%time clf.fit(train.text, train.lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим показания классификатора на тестовом множестве. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "predictions = clf.predict(test.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем результаты (например, в виде матрицы ошибок)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Важность признаков\n",
    "\n",
    "Веса признаков в линейной модели в случае, если признаки отмасштабированы, характеризуют степень их влияния на значение целевой переменной. В задаче классификации текстов, кроме того, признаки являются хорошо интерпретируемыми, поскольку каждый из них соответствует конкретному слову. Изучим влияние конкретных слов на значение целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_weights = zip(vectorizer.get_feature_names(), classifier.coef_[0])\n",
    "f_weights = sorted(f_weights, key=lambda i: i[1])\n",
    "for i in range(1,30):\n",
    "    print('%s, %.2f' % f_weights[-i])\n",
    "    \n",
    "print('...')\n",
    "for i in reversed(range(1,10)):\n",
    "    print('%s, %.2f' % f_weights[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание №2\n",
    "\n",
    "## Классификация новостей по темам\n",
    "\n",
    "Необходимо скачать датасет [20newsgroups](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html), выбрать несколько тем (не меньше 4, можно и все) и проделать то же самое с ними. В данном случае предсказывать мы будем тему новости, и, поскольку эта задача сложнее, можно сравнить качество при использовании лемматизации и без, при удалении стоп-слов и без, при разных способах векторизации (пока используем только счетные модели). Также необходимо сравнить разные методы классификации (хватит тех, что реализованы в sklearn), т.е. использовать не только NB."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
